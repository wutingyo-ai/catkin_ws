import os
from ultralytics import YOLO
import cv2
import numpy as np
from ultralytics.utils import ASSETS #å®˜ç¶²ç¯„ä¾‹ç¨‹å¼å¼•å…¥æ¨¡çµ„
from ultralytics.utils.checks import check_yaml #å®˜ç¶²ç¯„ä¾‹ç¨‹å¼å¼•å…¥æ¨¡çµ„
# import torch

class_names_dict={0: 'aluextru', 1: 'column', 2: 'twpipe'}
print(class_names_dict)

class_colors = {
    0: (0, 0, 255),   # é¡åˆ¥ 0 - ç´…è‰²
    1: (0, 255, 0),   # é¡åˆ¥ 1 - ç¶ è‰²
    2: (255, 0, 0),   # é¡åˆ¥ 2 - è—è‰²
    # æ·»åŠ æ›´å¤šé¡åˆ¥é¡è‰²
}

image_path_test='/home/chen/åœ–ç‰‡/test_segement/0_detect.png'
# è¨­å®šå·²å®Œæˆè¨“ç·´çš„è·¯å¾‘
# weight_path = r"/home/chen/Segmentation_Train/results/training_results5/weights/best.pt"
# weight_path = r"/home/chen/catkin_ws/src/pcl_with_gpd/weight/New_best.pt"
weight_path = r"/home/chen/catkin_ws/src/pcl_with_gpd/weight/2025_06_28_best.pt"


# åŠ è¼‰ YOLO æ¨¡å‹
model = YOLO(weight_path)

# è¨­å®šæ¸¬è©¦åœ–ç‰‡çš„è·¯å¾‘
# test_image_path = r"/home/chen/segmentation/new"
test_image_path = r"/home/chen/catkin_ws/src/pcl_with_gpd/picture"

# ç¢ºä¿æ¸¬è©¦åœ–ç‰‡å­˜åœ¨
if not os.path.exists(test_image_path):
    raise FileNotFoundError(f"æ¸¬è©¦åœ–ç‰‡ä¸å­˜åœ¨: {test_image_path}")


img_list=[]
# éæ­·è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰åœ–ç‰‡

for image_name in os.listdir(test_image_path):
    # ç¢ºä¿æ˜¯åœ–ç‰‡æª”æ¡ˆ
    if image_name.lower().endswith(('.jpg', '.jpeg', '.png')):
        image_path = os.path.join(test_image_path, image_name)
        img_list.append(image_path)
        # print(f"æ­£åœ¨è™•ç†åœ–ç‰‡: {image_path}")

def get_mask_data(image_path):
    results = model.predict(
        source=image_path,
        verbose=False,
        save=False,
        project="/home/chen/Segmentation_Train",
        name="view_1",
        show=False
    )

    # è®€å–åŸå§‹åœ–ç‰‡
    original_image = cv2.imread(image_path)
    orig_h, orig_w = original_image.shape[:2]  # åŸå§‹å°ºå¯¸
    mask_pixel_list = []
    class_id_list = []
    confidence_score_list = []

    for result in results:
        masks = result.masks
        classes = result.boxes.cls.cpu().numpy()
        confidence = result.boxes.conf.cpu().numpy()

        if masks is not None:
            for mask, cls, conf in zip(masks.data, classes, confidence):
                # mask: shape (640, 640) â†’ å…ˆè½‰ç‚º uint8 binary
                mask = mask.cpu().numpy().astype(np.uint8) * 255

                # ğŸ‘‰ ä¸Šæ¡æ¨£é®ç½©åˆ°åŸå§‹è§£æåº¦ï¼ˆå¦‚ 1280Ã—720ï¼‰
                mask_resized = cv2.resize(mask, (orig_w, orig_h), interpolation=cv2.INTER_NEAREST)

                confidence_score_list.append(conf)
                class_name = class_names_dict.get(int(cls), "Unknown")
                class_id_list.append(class_name)
                color = class_colors.get(int(cls), (255, 255, 255))

                # æ“·å–é®ç½©åƒç´ ä½ç½®
                y_coords, x_coords = np.where(mask_resized > 0)
                pixel_coords = np.stack([x_coords, y_coords], axis=1)  # shape: (N, 2)
                mask_pixel_list.append(pixel_coords)

                # ğŸ‘‰ ä»¥ä¸‹ç¹ªåœ–éƒ¨åˆ†å¥—ç”¨ resized é®ç½©
                contours, _ = cv2.findContours(mask_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(original_image, contours, -1, color, thickness=1)

                overlay = original_image.copy()
                overlay[mask_resized > 0] = color
                alpha = 0.5
                original_image = cv2.addWeighted(overlay, alpha, original_image, 1 - alpha, 0)

                # å¯é¸ï¼šåŠ ä¸Šé¡åˆ¥æ–‡å­—
                for contour in contours:
                    M = cv2.moments(contour)
                    if M["m00"] > 0:
                        cX = int(M["m10"] / M["m00"])
                        cY = int(M["m01"] / M["m00"])
                        cv2.putText(original_image, class_name, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX,
                                    0.6, color, 2, cv2.LINE_AA)

    return original_image, mask_pixel_list, class_id_list, confidence_score_list

def get_mask_data_accurate(image_path):
    results = model.predict(
        source=image_path,
        verbose=False,
        save=True,
        retina_masks=True,  # â† âœ… ç¢ºä¿è¼¸å‡ºé«˜è§£æåº¦é®ç½©
        device='cpu'
    )

    image = cv2.imread(image_path)
    h, w = image.shape[:2]

    all_pixel_coords = []
    class_id_list = []
    confidence_score_list = []
    # è¨­å®šä¿¡å¿ƒåˆ†æ•¸é–¾å€¼
    CONFIDENCE_THRESHOLD = 0.4  # ä½ å¯ä»¥èª¿æ•´é€™å€‹å€¼

    for result in results:
        masks = result.masks.data  # [n, h, w] torch.Tensor
        classes = result.boxes.cls.cpu().numpy()
        scores = result.boxes.conf.cpu().numpy()

        for i, (cls, conf) in enumerate(zip(classes, scores)):
            # 1. æª¢æŸ¥æ˜¯å¦é«˜æ–¼ä¿¡å¿ƒåˆ†æ•¸é–¾å€¼
            if conf < CONFIDENCE_THRESHOLD:
                continue  # è·³éæ­¤ç‰©ä»¶ï¼Œä¸è™•ç†é®ç½©æˆ–ç¹ªåœ–

            class_name = class_names_dict.get(int(cls), "Unknown")
            class_id_list.append(class_name)
            confidence_score_list.append(conf)

            # æå–å–®ä¸€ mask
            mask_tensor = masks[i]  # shape: (h, w)
            mask = mask_tensor.cpu().numpy().astype(np.uint8) * 255
            mask_resized = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)

            # ç²å–é®ç½©åƒç´ é»ä½ç½®
            y, x = np.where(mask_resized > 0)
            pixel_coords = np.stack([x, y], axis=1)
            all_pixel_coords.append(pixel_coords)

            # é®ç½©ä¸Šè‰²èˆ‡ç–ŠåŠ 
            color = class_colors.get(int(cls), (255, 255, 255))
            overlay = image.copy()
            contours, _ = cv2.findContours(mask_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            cv2.drawContours(overlay, contours, -1, color, thickness=cv2.FILLED)
            image = cv2.addWeighted(overlay, 0.5, image, 0.5, 0)

            # é‚Šæ¡†èˆ‡æ–‡å­—
            cv2.drawContours(image, contours, -1, color, thickness=2)
            for contour in contours:
                M = cv2.moments(contour)
                if M["m00"] > 0:
                    cX = int(M["m10"] / M["m00"])
                    cY = int(M["m01"] / M["m00"])
                    label = f"{class_name} {conf:.2f}"
                    cv2.putText(image, label, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    return image, all_pixel_coords, class_id_list, confidence_score_list

    # for result in results:
    #     masks = result.masks.data  # [n, h, w] torch.Tensor
    #     classes = result.boxes.cls.cpu().numpy()
    #     scores = result.boxes.conf.cpu().numpy()

    #     for i, (cls, conf) in enumerate(zip(classes, scores)):
    #         class_name = class_names_dict.get(int(cls), "Unknown")
    #         class_id_list.append(class_name)
    #         confidence_score_list.append(conf)
            
    #         # æå–å–®ä¸€ mask
    #         mask_tensor = masks[i]  # shape: (h, w)
    #         mask = mask_tensor.cpu().numpy().astype(np.uint8) * 255
    #         mask_resized = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)

    #         # ç²å–é®ç½©åƒç´ é»ä½ç½®
    #         y, x = np.where(mask_resized > 0)
    #         pixel_coords = np.stack([x, y], axis=1)
    #         all_pixel_coords.append(pixel_coords)

    #         # é®ç½©ä¸Šè‰²èˆ‡ç–ŠåŠ 
    #         color = class_colors.get(int(cls), (255, 255, 255))
    #         overlay = image.copy()
    #         contours, _ = cv2.findContours(mask_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    #         cv2.drawContours(overlay, contours, -1, color, thickness=cv2.FILLED)
    #         image = cv2.addWeighted(overlay, 0.5, image, 0.5, 0)

    #         # é‚Šæ¡†èˆ‡æ–‡å­—
    #         cv2.drawContours(image, contours, -1, color, thickness=2)
    #         for contour in contours:
    #             M = cv2.moments(contour)
    #             if M["m00"] > 0:
    #                 cX = int(M["m10"] / M["m00"])
    #                 cY = int(M["m01"] / M["m00"])
    #                 label = f"{class_name} {conf:.2f}"
    #                 cv2.putText(image, label, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

    return image, all_pixel_coords, class_id_list, confidence_score_list        

if __name__=="__main__":
    for image_path in img_list:
        image,mask_pixel_list,class_id_list,confidence_score_list=get_mask_data_accurate(image_path)
        zip_list=list(zip(mask_pixel_list,class_id_list,confidence_score_list))
        print(zip_list[0])               

        # é¡¯ç¤ºçµæœ
        cv2.namedWindow("segmentation_result",cv2.WINDOW_NORMAL)
        cv2.resizeWindow('segmentation_result',640,480) #(å¯¬,é«˜)
        cv2.imshow("segmentation_result", image)
        key=cv2.waitKey(0)  # æŒ‰ä»»æ„éµç¹¼çºŒ
        if key==ord('q'):
            cv2.destroyAllWindows()
            break

    

